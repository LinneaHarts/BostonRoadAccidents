{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Bike Collision and Other Data to Predict Car Accidents #\n",
    "## Data Collection and Cleaning ##\n",
    "\n",
    "Harvard University has collected a number of Boston Area data sets ffor their Boston Area Research Intitiative. The key data for this project about predicting bike accidents was derived from Boston Police Department incident narrative reports, as organized and compiled by Dahianna Lobez and partners ad BPD, BARI, and the Boston Cyclists Union.\n",
    "\n",
    "This data is for collisions that occured between 2009 and 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bike Collision Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import math\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "from pyproj import Proj, transform\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1808 entries, 0 to 1807\n",
      "Data columns (total 54 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   ID          1808 non-null   object        \n",
      " 1   YEAR        1797 non-null   float64       \n",
      " 2   DATE        1797 non-null   datetime64[ns]\n",
      " 3   DAY_WEEK    1795 non-null   object        \n",
      " 4   TIME        1797 non-null   object        \n",
      " 5   TYPE        1795 non-null   object        \n",
      " 6   SOURCE      1699 non-null   object        \n",
      " 7   XFINAL      1731 non-null   float64       \n",
      " 8   Xkm         1730 non-null   float64       \n",
      " 9   YFINAL      1731 non-null   float64       \n",
      " 10  Ykm         1731 non-null   float64       \n",
      " 11  Address     1730 non-null   object        \n",
      " 12  Main        1731 non-null   float64       \n",
      " 13  RoadType    1726 non-null   object        \n",
      " 14  ISINTERSEC  1807 non-null   float64       \n",
      " 15  TRACT       1731 non-null   float64       \n",
      " 16  CouncilDIS  1731 non-null   float64       \n",
      " 17  Councillor  1726 non-null   object        \n",
      " 18  PlanningDi  1726 non-null   object        \n",
      " 19  OIF1        1805 non-null   float64       \n",
      " 20  OIF2        1808 non-null   int64         \n",
      " 21  OIF3        1808 non-null   int64         \n",
      " 22  OIF4        1808 non-null   int64         \n",
      " 23  BLFinal     1808 non-null   int64         \n",
      " 24  CS          1808 non-null   int64         \n",
      " 25  LIGHTING    1557 non-null   object        \n",
      " 26  Indoor      1781 non-null   float64       \n",
      " 27  Light       1743 non-null   float64       \n",
      " 28  LightEng    1797 non-null   float64       \n",
      " 29  WEATHER     1594 non-null   object        \n",
      " 30  PrecipCond  1797 non-null   float64       \n",
      " 31  AtmosCondi  1797 non-null   float64       \n",
      " 32  DayNight    1797 non-null   float64       \n",
      " 33  Tmax        1797 non-null   float64       \n",
      " 34  Tmin        1797 non-null   float64       \n",
      " 35  Tavg        1797 non-null   float64       \n",
      " 36  Temprange   1797 non-null   float64       \n",
      " 37  SunriseTim  1797 non-null   object        \n",
      " 38  SunsetTime  1797 non-null   object        \n",
      " 39  SnowFall    1797 non-null   float64       \n",
      " 40  PrecipTota  1797 non-null   float64       \n",
      " 41  Fault       1807 non-null   float64       \n",
      " 42  Doored      1804 non-null   float64       \n",
      " 43  HelmetDocu  1807 non-null   float64       \n",
      " 44  TaxiFinal   1807 non-null   float64       \n",
      " 45  hitrunfina  1807 non-null   float64       \n",
      " 46  AlcoholFin  1807 non-null   float64       \n",
      " 47  INJURED     1804 non-null   float64       \n",
      " 48  TRANSPORTE  1804 non-null   float64       \n",
      " 49  TREATED     1804 non-null   float64       \n",
      " 50  GENDER      1730 non-null   object        \n",
      " 51  ETHNICITY   1730 non-null   object        \n",
      " 52  AGE         1669 non-null   float64       \n",
      " 53  Narrative   1806 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(32), int64(5), object(16)\n",
      "memory usage: 762.9+ KB\n"
     ]
    }
   ],
   "source": [
    "bike_df_orig = pd.read_excel('data/Final_Bike_Collision_Database.xlsx')\n",
    "bike_df_orig.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xkm** and **Ykm** encode the location of the accident. For this project I'm not interested in accidents that don't have a location, so I'll drop the rows with missing locations.\n",
    "\n",
    "I also want to make sure there aren't outliers in the location data. The Xkm and Ykm values are meter coordinates in a Massachusetts-specific geographic system. I'll convert them to latitude and logitude and make sure that they don't exceed the map of Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Right: \n",
      "42.385920811282396 -71.00003640589748\n",
      "Bottom Right:\n",
      "42.23530626734878 -71.00003640589748\n",
      "Top Right: \n",
      "42.385920811282396 -71.17443656586595\n",
      "Bottom Left: \n",
      "42.23530626734878 -71.17443656586595\n"
     ]
    }
   ],
   "source": [
    "bike_df = pd.DataFrame(bike_df_orig[(bike_df_orig.Xkm > 0) & (bike_df_orig.Ykm > 0)])\n",
    "\n",
    "# convert the bike data locations into latitude and longitudes and find the geographic extent\n",
    "inProj = Proj('epsg:26986')\n",
    "outProj = Proj('epsg:4326')\n",
    "xmax,ymax = bike_df['Xkm'].max(),bike_df['Ykm'].max()\n",
    "xmax2,ymax2 = transform(inProj,outProj,xmax,ymax)\n",
    "print ('Upper Right: ')\n",
    "print (xmax2,ymax2)\n",
    "\n",
    "xmin,ymin = bike_df['Xkm'].min(),bike_df['Ykm'].min()\n",
    "xmin2,ymin2 = transform(inProj,outProj,xmin,ymin)\n",
    "\n",
    "print('Bottom Right:')\n",
    "print(xmin2, ymax2)\n",
    "\n",
    "print('Top Right: ')\n",
    "print(xmax2, ymin2)\n",
    "\n",
    "print ('Bottom Left: ')\n",
    "print (xmin2,ymin2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other columns we may be interested in are RoadType and ISINTERSECT but we can find that data from our other data sets as well, so I'll consider data cleaning on Bike Collision data done at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output saved bike info for later use\n",
    "bike_df.to_csv(r'data/cleaned_data/bike_accident_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car Accident Data ###\n",
    "Car accident crash data is from kaggle. https://www.kaggle.com/sobhanmoosavi/us-accidents and shows car accidents in 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2974335"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df = pd.read_csv('data/US_Accidents_Dec19.csv')\n",
    "len(car_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a massive file with nearly 3 million rows and that covers the whole of the US, so the first task is to limit it to the same area as the bike accidents above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6343"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To capture accidents that may have happened at the edges of the bike collision area\n",
    "# keep accidents that either start or end within the area\n",
    "car_df = car_df[((car_df['Start_Lat'] <= xmax2) & (car_df['Start_Lat'] >= xmin2) & \n",
    "                 (car_df['Start_Lng'] <= ymax2) & (car_df['Start_Lng'] >= ymin2) |\n",
    "                (car_df['End_Lat'] <= xmax2) & (car_df['End_Lat'] >= xmin2) & \n",
    "                 (car_df['End_Lng'] <= ymax2) & (car_df['End_Lng'] >= ymin2))]\n",
    "\n",
    "# Re-index because we've removed a lot of values\n",
    "car_df = car_df.reset_index()\n",
    "\n",
    "len(car_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No other cleaning is necessary on this data, since the only thing I'm interested in is accident locations.\n",
    "\n",
    "The Mass DOT geospatial system is convenient for this project, so I'll add new columns to contain that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inProj = Proj('epsg:4326')\n",
    "outProj = Proj('epsg:26986')\n",
    "\n",
    "#loop through car datafram to create a list of lists containing the new coordinates\n",
    "points_list = []\n",
    "for index, row in car_df.iterrows():\n",
    "    points_row = []\n",
    "    start_points = list(transform(inProj,outProj,row['Start_Lat'],row['Start_Lng']))\n",
    "    points_row.append(start_points[0])\n",
    "    points_row.append(start_points[1])\n",
    "    end_points = list(transform(inProj,outProj,row['End_Lat'],row['End_Lng']))\n",
    "    points_row.append(end_points[0])\n",
    "    points_row.append(end_points[1])\n",
    "    points_list.append(points_row)\n",
    "\n",
    "converted_car_df = pd.DataFrame(points_list, columns=['Start_Xkm', 'Start_Ykm', 'End_Xkm', 'End_Ykm'])\n",
    "len(converted_car_df)\n",
    "#car_df[['Start_Xkm', 'Start_Ykm']] = transform(inProj,outProj,car_df['Start_Lat'],car_df['Start_Lng'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was an extremely time-consuming conversion. Here I've outputted the converted data for posterity so I don't have to do that again. Then I'm adding these as columns to the car data, and outputting that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output convered car accident locations for later use\n",
    "converted_car_df.to_csv(r'data/cleaned_data/converted_car_locs.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = pd.concat([car_df, converted_car_df], axis=1)\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.to_csv(r'data/cleaned_data/car_accidents_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Road Data ###\n",
    "Mass DOT has a database of road data in a .gpd file (https://geo-massdot.opendata.arcgis.com/datasets/road-inventory-2018). This has geometric data about the roads which will be very helpful, and a lot of qualitative road data with a code book [here](RI-DataDictionary.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to read in the full roads database, trim to only Boston data, and see if I can find the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_2018 = gpd.read_file('data\\RoadInv2018.gdb', layer=0)\n",
    "roads_2018.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To limit roads_2018 to only boston roads, I'll use geopandas functions to remove roads that aren't in the bike accident extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shape that contains all bike accidents using mins and maxes from above\n",
    "bike_shape = Polygon([(xmin, ymin), (xmin, ymax), (xmax, ymax), (xmax, ymin)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename geometry column so I don't lose it during the overlay\n",
    "roads_2018 = roads_2018.rename(columns={'geometry': 'road_shape'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to perform an interection, I need a column in roads_2018 that contains polygons\n",
    "roads_2018 = roads_2018.set_geometry('road_shape')\n",
    "roads_2018['buffer'] = roads_2018['road_shape'].buffer(50)\n",
    "roads_2018 = roads_2018.set_geometry('buffer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GeoDataFrame out of bike shape to enable overlay\n",
    "bike_df = gpd.GeoDataFrame({ 'shape': [bike_shape]})\n",
    "bike_df = bike_df.set_geometry('shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_gdf = gpd.overlay(bike_df, roads_2018, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rd_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot checking some values for outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_gdf['Surface_Wd'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_gdf['Med_Width'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "250m width for the road median seems like it might be an outlier, but it's not impossible on a highway. I may want to remove highways, but we'll see, and they don't make up many of the roads in Boston anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to file\n",
    "rd_gdf.to_csv(r'data/cleaned_data/boston_roads_gpd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
