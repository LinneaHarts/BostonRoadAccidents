{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the Best Models #\n",
    "\n",
    "In this notebook, I will select the top three best models and tune their hyperparameters to get the best fit. Classification has turned out to give better results than regression, so I will be tuning the models that can tell me where an accident is likely to occur, not how many accidents are likely to occur there.\n",
    "\n",
    "| Model | Vehicle | Accuracy |\n",
    "| ---- | ---- | ---- |\n",
    "| LogisticRegression | car | 0.645 | \n",
    "| LogisticRegression | bike | 0.474 | \n",
    "| KNeighborsClassifier | car | 0.844 | \n",
    "| KNeighborsClassifier | bike | 0.861 | \n",
    "| SVC | car | 0.834 | \n",
    "| SVC | bike | 0.788 | \n",
    "| LinearSVC | car | 0.681 | \n",
    "| LinearSVC | bike | 0.794 | \n",
    "| SGDClassifier | car | 0.719 | \n",
    "| SGDClassifier | bike | 0.762 | \n",
    "| DecisionTreeClassifier | car | 0.886 | \n",
    "| DecisionTreeClassifier | bike | 0.902 | \n",
    "| RandomForestClassifier | car | 0.885 | \n",
    "| RandomForestClassifier | bike | 0.908 | \n",
    "| BaggingClassifier | car | 0.895 | \n",
    "| BaggingClassifier | bike | 0.913 | \n",
    "| GradientBoostingClassifier | car | 0.885 | \n",
    "| GradientBoostingClassifier | bike | 0.895 | \n",
    "| AdaBoostClassifier | car | 0.859 | \n",
    "| AdaBoostClassifier | bike | 0.884 | \n",
    "\n",
    "\n",
    "So I will be tuning Decision Tree, Random Forest, Bagging, and Gradient Boosting to see which can give the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import graphviz\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data set with categorical variables turned into dummy variablees\n",
    "df = pd.read_csv('data/cleaned_data/md_dum.csv')\n",
    "\n",
    "# create X and y values for modeling, this time using a mask to create 1 and 0 values for classification\n",
    "car_c_y = df.car_acc_score.mask(df.car_acc_score > 0, 1)\n",
    "car_X = df.drop(columns=['Unnamed: 0', 'car_acc_score', 'car_dens_score', 'bike_dens_score'])\n",
    "bike_c_y = df.bike_acc_score.mask(df.bike_acc_score > 0, 1)\n",
    "bike_X = df.drop(columns=['Unnamed: 0', 'bike_acc_score', 'car_dens_score', 'bike_dens_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_car_c_train, X_car_c_test, y_car_c_train, y_car_c_test = train_test_split(car_X, car_c_y, test_size=0.3, \n",
    "                                                                            random_state=18,\n",
    "                                                                            shuffle=True, stratify=car_c_y)\n",
    "X_bike_c_train, X_bike_c_test, y_bike_c_train, y_bike_c_test = train_test_split(bike_X, bike_c_y, test_size=0.3, \n",
    "                                                                            random_state=18,\n",
    "                                                                            shuffle=True, stratify=bike_c_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for the best Decision Tree parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8881593740162792\n",
      "Tuned Model Parameters: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "params = {'criterion' : ['gini', 'entropy'],\n",
    "         'splitter' : ['best', 'random'],\n",
    "         'max_depth' : [10, 20, 50, 100],\n",
    "         'min_samples_split': [2, 5, 10]}\n",
    "dtc = tree.DecisionTreeClassifier(random_state=18)\n",
    "cv = GridSearchCV(dtc, params)\n",
    "cv.fit(X_car_c_train, y_car_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_car_c_test, y_car_c_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only slightly better than the original decision tree classifier. Trying again with some different parameters, but I may want to tune some other ensemble methods and see if they can be made better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8881593740162792\n",
      "Tuned Model Parameters: {'max_depth': 75}\n"
     ]
    }
   ],
   "source": [
    "dtc = tree.DecisionTreeClassifier(criterion='entropy', splitter='best', min_samples_split=2, random_state=18)\n",
    "params = {'max_depth': [60, 75, 100, 200, 300, 400, 500]}\n",
    "cv = GridSearchCV(dtc, param_grid=params)\n",
    "cv.fit(X_car_c_train, y_car_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_car_c_test, y_car_c_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning for bikes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9046633988397715\n",
      "Tuned Model Parameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 2, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "params = {'criterion' : ['gini', 'entropy'],\n",
    "         'splitter' : ['best', 'random'],\n",
    "         'max_depth' : [10, 20, 50, 100],\n",
    "         'min_samples_split': [2, 5, 10]}\n",
    "dtc = tree.DecisionTreeClassifier(random_state=18)\n",
    "cv = GridSearchCV(dtc, params)\n",
    "cv.fit(X_bike_c_train, y_bike_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_bike_c_test, y_bike_c_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brings the accuracy up close to the level of the other ensemble methods, at least without performance tuning.\n",
    "\n",
    "Now tuning Random Forest on cars. Even doing Randomized Search CV took a very long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.895444529387957\n",
      "Tuned Model Parameters: {'n_estimators': 100, 'min_samples_split': 2, 'max_features': None, 'max_depth': 100}\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(criterion='entropy', random_state=18)\n",
    "params = {'n_estimators': [10, 100, 500, 1000],\n",
    "         'max_depth' : [10, 50, 100, 200],\n",
    "         'max_features' : ['sqrt', 'log2', None],\n",
    "         'min_samples_split': [2, 5, 10]}\n",
    "cv = RandomizedSearchCV(rfc, params)\n",
    "cv.fit(X_car_c_train, y_car_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_car_c_test, y_car_c_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found some good parameters here but tried again a few  times to see if I could get better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8964788415703557\n",
      "Tuned Model Parameters: {'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(criterion='entropy', min_samples_split=2, max_features=None, random_state=18)\n",
    "params = {'n_estimators': [50, 100, 200, 300, 400, 500, 1000]}\n",
    "cv = GridSearchCV(rfc, params)\n",
    "cv.fit(X_car_c_train, y_car_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_car_c_test, y_car_c_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8965238116652426\n",
      "Tuned Model Parameters: {'max_depth': 75}\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(criterion='entropy', \n",
    "                                      n_estimators=400,\n",
    "                                      min_samples_split=2, \n",
    "                                      max_features=None, \n",
    "                                      random_state=18)\n",
    "params = {'max_depth': [75, 100, 125, 150]}\n",
    "cv = GridSearchCV(rfc, params)\n",
    "cv.fit(X_car_c_train, y_car_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_car_c_test, y_car_c_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8964788415703557\n",
      "Tuned Model Parameters: {'max_depth': 65, 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(criterion='entropy', \n",
    "                                      n_estimators=400,\n",
    "                                      min_samples_split=2, \n",
    "                                      random_state=18)\n",
    "params = {'max_depth': [65, 75],\n",
    "         'max_features':[None, 'sqrt', 'log2']}\n",
    "cv = GridSearchCV(rfc, params)\n",
    "cv.fit(X_car_c_train, y_car_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_car_c_test, y_car_c_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying the tuned parameters on bike accidents, and it improves that score as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.918918918918919\n",
      "[[17030   496]\n",
      " [ 1307  3404]]\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(criterion='entropy', \n",
    "                                      n_estimators=400,\n",
    "                                      min_samples_split=2, \n",
    "                                      max_depth=75,\n",
    "                                      max_features=None,\n",
    "                                      random_state=18)\n",
    "rfc.fit(X_bike_c_train, y_bike_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(rfc.score(X_bike_c_test, y_bike_c_test)))\n",
    "pred = rfc.predict(X_bike_c_test)\n",
    "c=confusion_matrix(y_bike_c_test, pred)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tuning Bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.895489499482844\n",
      "Tuned Model Parameters: {'max_features': 0.75, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "bgc = ensemble.BaggingClassifier(random_state=18)\n",
    "params = {'n_estimators': [10, 100, 500, 1000],\n",
    "         'max_features' : [0.25, 0.5, 0.75]}\n",
    "cv = GridSearchCV(bgc, params)\n",
    "cv.fit(X_car_c_train, y_car_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_car_c_test, y_car_c_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.895489499482844\n",
      "Tuned Model Parameters: {'max_features': 0.75, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "bgc = ensemble.BaggingClassifier(random_state=18)\n",
    "params = {'n_estimators': [500, 650, 800],\n",
    "         'max_features' : [0.75, .9, 1.0]}\n",
    "cv = GridSearchCV(bgc, params)\n",
    "cv.fit(X_car_c_train, y_car_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_car_c_test, y_car_c_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying tuned parameters on bikes. Performs very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9217520348967936\n",
      "[[17029   497]\n",
      " [ 1243  3468]]\n"
     ]
    }
   ],
   "source": [
    "bgc = ensemble.BaggingClassifier(random_state=18, max_features=0.75, n_estimators=500)\n",
    "bgc.fit(X_bike_c_train, y_bike_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(bgc.score(X_bike_c_test, y_bike_c_test)))\n",
    "pred = bgc.predict(X_bike_c_test)\n",
    "c = confusion_matrix(y_bike_c_test, pred)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8934208751180465\n",
      "Tuned Model Parameters: {'n_estimators': 500, 'min_samples_split': 20, 'max_features': None, 'max_depth': 10, 'learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier(random_state=18)\n",
    "params = {'n_estimators': [10, 100, 500, 1000],\n",
    "          'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "          'max_depth' : [2, 3, 5, 10],\n",
    "          'max_features': ['sqrt', 'log2', None],\n",
    "          'min_samples_split': [2, 5, 10, 20]}\n",
    "cv = RandomizedSearchCV(gbc, params)\n",
    "cv.fit(X_car_c_train, y_car_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_car_c_test, y_car_c_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8949498583442012\n",
      "Tuned Model Parameters: {'min_samples_split': 5, 'max_depth': 15, 'learning_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier(random_state=18, n_estimators=500, max_features=None)\n",
    "params = {'learning_rate': [0.3, 0.5, 0.7, 0.9],\n",
    "          'max_depth' : [7, 10, 15, 20],\n",
    "          'min_samples_split': [5, 20, 30]}\n",
    "cv = RandomizedSearchCV(gbc, params)\n",
    "cv.fit(X_car_c_train, y_car_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_car_c_test, y_car_c_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying tuned parameters on bike accident data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7627827494716014\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier(random_state=18, n_estimators=500, max_features=None,\n",
    "                                         min_samples_split=5, max_depth=15, learning_rate=0.3)\n",
    "gbc.fit(X_bike_c_train, y_bike_c_train)\n",
    "print(\"Accuracy: {}\".format(cv.score(X_bike_c_test, y_bike_c_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is not good, so bike accident data may need different hyperparameters for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9128479561091873\n",
      "Tuned Model Parameters: {'n_estimators': 100, 'min_samples_split': 20, 'max_features': None, 'max_depth': 10, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier(random_state=18)\n",
    "params = {'n_estimators': [10, 100, 500, 1000],\n",
    "          'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "          'max_depth' : [2, 3, 5, 10, 15, 20],\n",
    "          'max_features': ['sqrt', 'log2', None],\n",
    "          'min_samples_split': [2, 5, 10, 20]}\n",
    "cv = RandomizedSearchCV(gbc, params)\n",
    "cv.fit(X_bike_c_train, y_bike_c_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(cv.score(X_bike_c_test, y_bike_c_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, that is much better. \n",
    "\n",
    "Since accidents may happen in the future, it wouldn't make sense to have perfect accuracy. \n",
    "\n",
    "Next I will use the best-performing models on a subset of features, to see if I get better results or at least faster-performing models. [Go>>](Feature%20Selection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
